# Data_Science_in_Practice

PySpark mini-project for **Income Classification**.  
Developed for the **Postgraduate Diploma in Data Science (Wits University, 2025)**.

---

## ğŸ¯ Project Objective
This project applies scalable machine learning techniques in **Apache Spark (PySpark)** to predict whether a personâ€™s income exceeds a certain threshold based on demographic and employment attributes.

---

## ğŸ§° Tools & Technologies
- ğŸª¶ **Apache Spark (PySpark)**
- ğŸ”¢ **Spark MLlib**
- ğŸ§© **StringIndexer**, **VectorAssembler**, **Pipeline**
- ğŸŒ² **DecisionTreeClassifier** and **RandomForestClassifier**
- ğŸ“ **MulticlassClassificationEvaluator**

---

## ğŸ“Š Dataset
- **File:** [`data/income.csv`](data/income.csv)
- The dataset contains demographic and employment features (e.g., age, education, occupation, workclass).
- The target variable is **`income_class`** (binary classification).

---

## ğŸ§ª Methodology
1. Load and clean dataset (`income.csv`)
2. Drop missing values
3. Encode categorical variables using **StringIndexer**
4. Combine numerical and encoded features with **VectorAssembler**
5. Split into **training (80%)** and **testing (20%)**
6. Train and evaluate **Decision Tree** and **Random Forest** models
7. Report model performance metrics

---

## ğŸ“ˆ Results Summary
| Model | Accuracy |
|--------|-----------|
| Decision Tree | ~85% |
| Random Forest | ~89% |

> ğŸ† The Random Forest model outperformed the Decision Tree due to ensemble averaging, leading to better generalization.

---

## ğŸš€ How to Run the Code
1. Ensure Spark is installed locally.
2. Place `income.csv` in the `/data` folder.
3. Run the script from the command line:
   ```bash
   spark-submit src/Assessment2_Income.py
